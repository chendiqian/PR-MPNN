program: main.py
method: bayes
entity: mls-stuttgart
project: nci1-sweep-10fold
name: nci1-sweep-10fold
run_cap: 100

metric:
  goal: maximize
  name: final_metric

parameters:
  # read data
  dataset:
    value: nci1
  log_path:
    value: './logs'
  data_path:
    value: './datasets'

  # debugger mode
  num_runs:
    value: 1
  use_wandb:
    value: True
  debug:
    value: False

  # sample configs, shared by random and learnable sampling methods
  sample_configs.sample_policy:
    value: edge_candid
  sample_configs.in_place:
    value: True
  sample_configs.per_layer:
    value: False
  sample_configs.separate:
    value: False
  sample_configs.directed:
    value: False
  sample_configs.heuristic:
    value: longest_path
  sample_configs.sample_k:  # add edges
    values:
      - 0
      - 5
      - 10
      - 25
      - 50
      - 75
      - 100
    distribution: categorical
  sample_configs.sample_k2:  # rm edges
    values:
      - 0
      - 5
      - 10
      - 25
      - 50
      - 75
      - 100
    distribution: categorical
  sample_configs.candid_pool:
    values:
      - 1024
    distribution: categorical
  sample_configs.ensemble:
    values:
      # - 1
      - 2
      - 3
    distribution: categorical
  sample_configs.include_original_graph:
    values: 
      - True
      - False
    distribution: categorical

  # sampler and its hyperparams
  imle_configs.sampler:
    value: simple
  imle_configs.logits_activation:
    value: None
  imle_configs.negative_sample:
    value: full
  imle_configs.num_train_ensemble:
    values:
      # - 1
      - 2
      - 5
    distribution: categorical
  imle_configs.num_val_ensemble:
    values:
      # - 1
      - 2
      - 5
    distribution: categorical

  # weighting the edges
  imle_configs.weight_edges:
    values:
      - marginals
      # - None
    distribution: categorical
  imle_configs.marginals_mask:
    value: True

  # upstream model
  imle_configs.model:
    value: "edge_selector"
  # imle_configs.rwse.kernel:
  #   value: 20
  # imle_configs.rwse.layers:
  #   value: 2
  # imle_configs.rwse.dim_pe:
  #   value: 32
  # imle_configs.rwse.raw_norm_type:
  #   value: 'BatchNorm'

  imle_configs.emb_hid_size:
    values:
      - 32
    distribution: categorical
  imle_configs.gnn_layer:
    values:
      - 4
      - 8
      - 16
    distribution: categorical
  imle_configs.mlp_layer:
    values:
      - 2
    distribution: categorical
  imle_configs.dropout:
    value: 0.

  # upstream training
  imle_configs.embd_lr:
    value: 1.e-3
  imle_configs.emb_optim:
    value: adamw
  imle_configs.emb_scheduler:
    value: None
  imle_configs.reg_embd:
    value: 0.
  imle_configs.batchnorm:
    value: True
  imle_configs.micro_batch_embd:
    value: 1

  # downstream model
  model:
    value: gine_duo
  hid_size:
    value: 32
  num_convlayers:
    value: 4
  mlp_layers_intragraph:
    value: 3
  mlp_layers_intergraph:
    value: 1
  graph_pooling:
    value: mean
  dropout:
    value: 0.1
  bn:
    value: True
  residual:
    value: True
  inter_graph_pooling:
    value: cat

  # downstream training
  # rwse.kernel:
  #   value: 20
  # rwse.layers:
  #   value: 2
  # rwse.dim_pe:
  #   value: 32
  # rwse.raw_norm_type:
  #   value: 'BatchNorm'

  lr:
    value: 1.e-3
  lr_decay.scheduler:
    value: plateau
  lr_decay.mode:
    value: max
  lr_decay.decay_rate:
    value: 0.5
  lr_decay.patience:
    value: 30
  lr_decay.target:
    value: val_metric_ensemble
  optim:
    value: adam
  early_stop.patience:
    value: 50
  early_stop.target:
    value: val_metric_ensemble
  # early_stop.eval_test_at_best:
  #   value: True
  reg:
    value: 0.
  batch_size:
    value: 128
  min_epochs:
    value: 200
  max_epochs:
    value: 1000
