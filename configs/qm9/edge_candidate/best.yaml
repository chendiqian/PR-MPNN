fixed:
  dataset: qm9
  log_path: './logs'

  use_wandb: False
  wandb_name: "best_edge_candid"

  sample_configs:
    sample_policy: edge_candid
    per_layer: False
    separate: False
    directed: False
    in_place: True
    sample_k: 80   # edge addition
    sample_k2: 20   # edge deletion
    candid_pool: 100
    ensemble: 1
    heuristic: longest_path
    include_original_graph: True

  imle_configs:
    sampler: imle
    noise_scale: 0.3
    beta: 10.
    logits_activation: null
    weight_edges: null
    marginals_mask: True
    negative_sample: 'full'
    num_train_ensemble: 1
    num_val_ensemble: 1

    model: "edge_selector"
    emb_hid_size: 64
    emb_optim: "adamw"
    emb_scheduler: None
    gnn_layer: 8
    mlp_layer: 4
    dropout: 0.
    embd_lr: 1.e-3
    reg_embd: 0.
    batchnorm: True


  task_id: 0  # remove task_id to train on all
  optim: "adam"
  model: qm9gine_duo
  hid_size: 256
  lr: 1.e-3
  lr_decay:
    scheduler: 'plateau'
    decay_rate: 0.5
    mode: 'max'
    patience: 150
    target: 'val_metric'
  early_stop:
    patience: 200
    target: val_metric
  reg: 0.
  num_convlayers: 4
  mlp_layers_intragraph: 0
  mlp_layers_intergraph: 2
  graph_pooling: max
  inter_graph_pooling: cat
  dropout: 0.5
  bn: True  # placeholder
  residual: True  # placeholder
  batch_size: 4
  min_epochs: 400
  max_epochs: 1000
  data_path: './datasets'
  debug: True
  num_runs: 1
#
#  plot_graphs:
#    batch_id: 0
#    plot_every: 100
#    n_graphs: 5
#    plot_folder: './plots'

#  connectedness:
#    metric: eigval
#    every: 10